{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "N-gram scores are a simple count of the number of overlapping n-grams between the generated summary and the original text."
      ],
      "metadata": {
        "id": "8Ma26ZnCzlPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code uses bi-grams (n=2) and the CountVectorizer from sklearn to count the number of common bi-grams between the generated summary and the original text. You can change the value of n in the ngram_overlap function if you want to use different n-grams (e.g., tri-grams, 4-grams, etc.)."
      ],
      "metadata": {
        "id": "S9ePsSfHzq6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Average N-gram Score of 96.49 suggests a high degree of similarity between the two sets of text that are being compared. In N-gram comparison, text is broken down into chunks (n-grams) and then these chunks are compared between the two sets of text to see how many of them match.\n",
        "\n",
        "Here are a few things to consider when interpreting this score:\n",
        "\n",
        "Length of Texts: Longer texts will naturally have more n-grams, and therefore higher scores. Comparing this score between texts of very different lengths can be misleading.\n",
        "\n",
        "Dataset Specific: It's important to understand how this score relates to your specific dataset. If you're comparing systems or methods, it's useful to compare the N-gram scores relative to each other rather than as an absolute value.\n",
        "\n",
        "Complement Other Metrics: It's also useful to look at this metric in conjunction with other metrics like ROUGE or BLEU, as N-gram overlap alone doesn't account for order or semantic similarity.\n",
        "\n",
        "\n",
        "while a score of 96.49 suggests a high degree of overlap in terms of n-grams, interpreting whether this is good or bad, or what it indicates, requires more context about how the score was calculated and what it's being used to evaluate."
      ],
      "metadata": {
        "id": "eZeU_dgF4sfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"Abstract_Summary_t5_base_file.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the N-gram scores\n",
        "ngram_scores = []\n",
        "\n",
        "# Define a function to compute N-gram overlap\n",
        "def ngram_overlap(text1, text2, n=2):\n",
        "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
        "    ngram_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    overlap = np.dot(ngram_matrix[0].toarray(), ngram_matrix[1].toarray().T)\n",
        "    return overlap[0, 0]\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the original text and the generated summary\n",
        "    abstract = row['Abstract']\n",
        "\n",
        "    # Clean the abstract\n",
        "    abstract = re.sub(r'[^\\x00-\\x7F]+', '', str(abstract))\n",
        "\n",
        "    # Combine the cleaned abstract\n",
        "    original_text = abstract\n",
        "    generated_summary = str(row['Abstract_Summary_t5_base'])\n",
        "\n",
        "    # Calculate N-gram overlap (using bi-grams)\n",
        "    ngram_score = ngram_overlap(generated_summary, original_text, 2)\n",
        "\n",
        "    # Append the score to the list\n",
        "    ngram_scores.append(ngram_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['N-gram_Score'] = ngram_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Summary_Scores_Ngram_t5_base_abstract_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average score\n",
        "print(\"\\nAverage N-gram Score:\", sum(ngram_scores) / len(ngram_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjV3NS__zm_I",
        "outputId": "66774b01-96d7-47ac-c785-4954128c19e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:02<00:00, 803.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average N-gram Score: 59.287116564417175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"Claims_Summary_t5_base_file.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the N-gram scores\n",
        "ngram_scores = []\n",
        "\n",
        "# Define a function to compute N-gram overlap\n",
        "def ngram_overlap(text1, text2, n=2):\n",
        "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
        "    ngram_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    overlap = np.dot(ngram_matrix[0].toarray(), ngram_matrix[1].toarray().T)\n",
        "    return overlap[0, 0]\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the original text and the generated summary\n",
        "    claims = row['Claims']\n",
        "\n",
        "    # Clean the abstract\n",
        "    claims = re.sub(r'[^\\x00-\\x7F]+', '', str(claims))\n",
        "\n",
        "    # Combine the cleaned abstract\n",
        "    original_text = claims\n",
        "    generated_summary = str(row['Claims_Summary_t5_base'])\n",
        "\n",
        "    # Calculate N-gram overlap (using bi-grams)\n",
        "    ngram_score = ngram_overlap(generated_summary, original_text, 2)\n",
        "\n",
        "    # Append the score to the list\n",
        "    ngram_scores.append(ngram_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['N-gram_Score'] = ngram_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Summary_Scores_Ngram_t5_base_claims_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average score\n",
        "print(\"\\nAverage N-gram Score:\", sum(ngram_scores) / len(ngram_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEJc9Ijez-tJ",
        "outputId": "49692df5-3ad1-4116-9f02-62a4d9d3f64d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:06<00:00, 267.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average N-gram Score: 590.2257668711657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"Combined_Google_patent_Summary_t5_base_file.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the N-gram scores\n",
        "ngram_scores = []\n",
        "\n",
        "# Define a function to compute N-gram overlap\n",
        "def ngram_overlap(text1, text2, n=2):\n",
        "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
        "    ngram_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    overlap = np.dot(ngram_matrix[0].toarray(), ngram_matrix[1].toarray().T)\n",
        "    return overlap[0, 0]\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the original text and the generated summary\n",
        "    abstract = row['Abstract_Summary_t5_base']\n",
        "    claims = row['Claims_Summary_t5_base']\n",
        "\n",
        "    # Clean the abstract\n",
        "    abstract = re.sub(r'[^\\x00-\\x7F]+', '', str(abstract))\n",
        "    claims = re.sub(r'[^\\x00-\\x7F]+', '', str(claims))\n",
        "\n",
        "    # Combine the cleaned abstract\n",
        "    original_text = abstract+' '+claims\n",
        "    generated_summary = str(row['Combined_Summary'])\n",
        "\n",
        "    # Calculate N-gram overlap (using bi-grams)\n",
        "    ngram_score = ngram_overlap(generated_summary, original_text, 2)\n",
        "\n",
        "    # Append the score to the list\n",
        "    ngram_scores.append(ngram_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['N-gram_Score'] = ngram_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Summary_Scores_Ngram_t5_base_combined_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average score\n",
        "print(\"Average N-gram Score:\", sum(ngram_scores) / len(ngram_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVDLHSR50a55",
        "outputId": "6df5aaac-f11e-4eda-d374-019f2dc23b46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:01<00:00, 851.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average N-gram Score: 53.09263803680982\n"
          ]
        }
      ]
    }
  ]
}
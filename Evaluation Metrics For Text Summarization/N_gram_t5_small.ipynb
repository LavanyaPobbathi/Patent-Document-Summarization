{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "N-gram scores are a simple count of the number of overlapping n-grams between the generated summary and the original text."
      ],
      "metadata": {
        "id": "8Ma26ZnCzlPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code uses bi-grams (n=2) and the CountVectorizer from sklearn to count the number of common bi-grams between the generated summary and the original text. You can change the value of n in the ngram_overlap function if you want to use different n-grams (e.g., tri-grams, 4-grams, etc.)."
      ],
      "metadata": {
        "id": "S9ePsSfHzq6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Average N-gram Score of 96.49 suggests a high degree of similarity between the two sets of text that are being compared. In N-gram comparison, text is broken down into chunks (n-grams) and then these chunks are compared between the two sets of text to see how many of them match.\n",
        "\n",
        "Here are a few things to consider when interpreting this score:\n",
        "\n",
        "Length of Texts: Longer texts will naturally have more n-grams, and therefore higher scores. Comparing this score between texts of very different lengths can be misleading.\n",
        "\n",
        "Dataset Specific: It's important to understand how this score relates to your specific dataset. If you're comparing systems or methods, it's useful to compare the N-gram scores relative to each other rather than as an absolute value.\n",
        "\n",
        "Complement Other Metrics: It's also useful to look at this metric in conjunction with other metrics like ROUGE or BLEU, as N-gram overlap alone doesn't account for order or semantic similarity.\n",
        "\n",
        "\n",
        "while a score of 96.49 suggests a high degree of overlap in terms of n-grams, interpreting whether this is good or bad, or what it indicates, requires more context about how the score was calculated and what it's being used to evaluate."
      ],
      "metadata": {
        "id": "eZeU_dgF4sfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"abstract_summary_t5_small.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the N-gram scores\n",
        "ngram_scores = []\n",
        "\n",
        "# Define a function to compute N-gram overlap\n",
        "def ngram_overlap(text1, text2, n=2):\n",
        "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
        "    ngram_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    overlap = np.dot(ngram_matrix[0].toarray(), ngram_matrix[1].toarray().T)\n",
        "    return overlap[0, 0]\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the original text and the generated summary\n",
        "    abstract = row['Abstract']\n",
        "\n",
        "    # Clean the abstract\n",
        "    abstract = re.sub(r'[^\\x00-\\x7F]+', '', str(abstract))\n",
        "\n",
        "    # Combine the cleaned abstract\n",
        "    original_text = abstract\n",
        "    generated_summary = str(row['Abstract_Summary'])\n",
        "\n",
        "    # Calculate N-gram overlap (using bi-grams)\n",
        "    ngram_score = ngram_overlap(generated_summary, original_text, 2)\n",
        "\n",
        "    # Append the score to the list\n",
        "    ngram_scores.append(ngram_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['N-gram_Score'] = ngram_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Summary_Scores_Ngram_t5_small_abstract_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average score\n",
        "print(\"Average N-gram Score:\", sum(ngram_scores) / len(ngram_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjV3NS__zm_I",
        "outputId": "71560be4-37ec-4eb8-a984-3b0fc7ac7837"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:02<00:00, 765.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average N-gram Score: 96.4877300613497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"claim_summary_t5_small.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the N-gram scores\n",
        "ngram_scores = []\n",
        "\n",
        "# Define a function to compute N-gram overlap\n",
        "def ngram_overlap(text1, text2, n=2):\n",
        "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
        "    ngram_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    overlap = np.dot(ngram_matrix[0].toarray(), ngram_matrix[1].toarray().T)\n",
        "    return overlap[0, 0]\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the original text and the generated summary\n",
        "    claims = row['Claims']\n",
        "\n",
        "    # Clean the abstract\n",
        "    claims = re.sub(r'[^\\x00-\\x7F]+', '', str(claims))\n",
        "\n",
        "    # Combine the cleaned abstract\n",
        "    original_text = claims\n",
        "    generated_summary = str(row['claim_Summary'])\n",
        "\n",
        "    # Calculate N-gram overlap (using bi-grams)\n",
        "    ngram_score = ngram_overlap(generated_summary, original_text, 2)\n",
        "\n",
        "    # Append the score to the list\n",
        "    ngram_scores.append(ngram_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['N-gram_Score'] = ngram_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Summary_Scores_Ngram_t5_small_claims_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average score\n",
        "print(\"Average N-gram Score:\", sum(ngram_scores) / len(ngram_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEJc9Ijez-tJ",
        "outputId": "3fd212da-f962-49cc-ce13-8c7d6f6350c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:05<00:00, 302.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average N-gram Score: 747.4975460122699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"Combined_Google_patent_Summary_t5_small_score.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the N-gram scores\n",
        "ngram_scores = []\n",
        "\n",
        "# Define a function to compute N-gram overlap\n",
        "def ngram_overlap(text1, text2, n=2):\n",
        "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
        "    ngram_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    overlap = np.dot(ngram_matrix[0].toarray(), ngram_matrix[1].toarray().T)\n",
        "    return overlap[0, 0]\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the original text and the generated summary\n",
        "    abstract = row['Abstract_Summary']\n",
        "    claims = row['claim_Summary']\n",
        "\n",
        "    # Clean the abstract\n",
        "    abstract = re.sub(r'[^\\x00-\\x7F]+', '', str(abstract))\n",
        "    claims = re.sub(r'[^\\x00-\\x7F]+', '', str(claims))\n",
        "\n",
        "    # Combine the cleaned abstract\n",
        "    original_text = abstract+' '+claims\n",
        "    generated_summary = str(row['Combined_Summary'])\n",
        "\n",
        "    # Calculate N-gram overlap (using bi-grams)\n",
        "    ngram_score = ngram_overlap(generated_summary, original_text, 2)\n",
        "\n",
        "    # Append the score to the list\n",
        "    ngram_scores.append(ngram_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['N-gram_Score'] = ngram_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Summary_Scores_Ngram_t5_small_combined_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average score\n",
        "print(\"Average N-gram Score:\", sum(ngram_scores) / len(ngram_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVDLHSR50a55",
        "outputId": "dbaa377c-706d-437f-ee16-33caad6bb31d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:02<00:00, 785.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average N-gram Score: 138.05705521472393\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DCRS is the Dale-Chall Readability Score, PDW is the Percentage of Difficult Words, and ASL is the Average Sentence Length.\n",
        "\n",
        "The resulting score can be interpreted as follows:\n",
        "\n",
        "4.9 or below: Easily understandable by an average 4th-grade student or lower.\n",
        "\n",
        "5.0–5.9: Easily understandable by an average 5th or 6th-grade student.\n",
        "\n",
        "6.0–6.9: Easily understandable by an average 7th or 8th-grade student.\n",
        "\n",
        "7.0–7.9: Easily understandable by an average 9th or 10th-grade student.\n",
        "\n",
        "8.0–8.9: Easily understandable by an average 11th or 12th-grade student.\n",
        "\n",
        "9.0–9.9: Easily understandable by an average college student.\n",
        "\n",
        "10.0 or above: Only easily understandable by graduates or individuals with a higher level of education.\n"
      ],
      "metadata": {
        "id": "wJtKmfW8rJgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHxTOw7_sSWu",
        "outputId": "53bf3b3a-dcc9-44fa-8145-1dff7dd41148"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/105.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import textstat\n",
        "import re\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"abstract_summary_t5_small.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the Dale-Chall Readability scores\n",
        "dcr_scores = []\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the abstract summary\n",
        "    abstract_summary = str(row['Abstract_Summary'])\n",
        "\n",
        "    # Clean the abstract summary\n",
        "    abstract_summary = re.sub(r'[^\\x00-\\x7F]+', '', abstract_summary)\n",
        "\n",
        "    # Calculate Dale-Chall Readability score\n",
        "    dcr_score = textstat.dale_chall_readability_score(abstract_summary)\n",
        "\n",
        "    # Append the score to the list\n",
        "    dcr_scores.append(dcr_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['Dale_Chall_Readability_Score'] = dcr_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Dale_Chall_Readability_Scores_t5_small_abstract_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average Dale-Chall Readability Score\n",
        "print(\"Average Dale-Chall Readability Score:\", sum(dcr_scores) / len(dcr_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMDHH2uvrJ4B",
        "outputId": "09c35791-b56e-4ea1-e182-f15af4bc0768"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:00<00:00, 4082.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Dale-Chall Readability Score: 9.98220245398774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import textstat\n",
        "import re\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"claim_summary_t5_small.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the Dale-Chall Readability scores\n",
        "dcr_scores = []\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the abstract summary\n",
        "    claim_Summary = str(row['claim_Summary'])\n",
        "\n",
        "    # Clean the abstract summary\n",
        "    claim_Summary = re.sub(r'[^\\x00-\\x7F]+', '', claim_Summary)\n",
        "\n",
        "    # Calculate Dale-Chall Readability score\n",
        "    dcr_score = textstat.dale_chall_readability_score(claim_Summary)\n",
        "\n",
        "    # Append the score to the list\n",
        "    dcr_scores.append(dcr_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['Dale_Chall_Readability_Score'] = dcr_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Dale_Chall_Readability_Scores_t5_small_claims_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average Dale-Chall Readability Score\n",
        "print(\"Average Dale-Chall Readability Score:\", sum(dcr_scores) / len(dcr_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxkqVqD9sdyx",
        "outputId": "694a67c8-6fc1-427d-e652-3c361165f42c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:00<00:00, 4755.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Dale-Chall Readability Score: 9.383355828220886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import textstat\n",
        "import re\n",
        "\n",
        "# Load the DataFrame from the Excel file\n",
        "input_file = \"Combined_Google_patent_Summary_t5_small_score.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define a list to store the Dale-Chall Readability scores\n",
        "dcr_scores = []\n",
        "\n",
        "# Iterate over the rows in the DataFrame with a progress bar\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating Scores\"):\n",
        "    # Get the abstract summary\n",
        "    Combined_Summary = str(row['Combined_Summary'])\n",
        "\n",
        "    # Clean the abstract summary\n",
        "    Combined_Summary = re.sub(r'[^\\x00-\\x7F]+', '', Combined_Summary)\n",
        "\n",
        "    # Calculate Dale-Chall Readability score\n",
        "    dcr_score = textstat.dale_chall_readability_score(Combined_Summary)\n",
        "\n",
        "    # Append the score to the list\n",
        "    dcr_scores.append(dcr_score)\n",
        "\n",
        "# Add the scores to the DataFrame\n",
        "df['Dale_Chall_Readability_Score'] = dcr_scores\n",
        "\n",
        "# Save the updated DataFrame to a new Excel file\n",
        "output_file = \"Dale_Chall_Readability_Scores_t5_small_combined_total.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "# Print the average Dale-Chall Readability Score\n",
        "print(\"Average Dale-Chall Readability Score:\", sum(dcr_scores) / len(dcr_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO1maswrsvCF",
        "outputId": "eaa332fc-cfd6-4bdb-db4f-7a71d847aac9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Scores: 100%|██████████| 1630/1630 [00:00<00:00, 5075.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Dale-Chall Readability Score: 9.098306748466253\n"
          ]
        }
      ]
    }
  ]
}